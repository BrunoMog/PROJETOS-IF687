{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WECeh57QhL9O"
      ],
      "authorship_tag": "ABX9TyMtcAuo+e6CNE6iftoqs0A+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoMog/PROJETOS-IF687/blob/main/mlp_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Início da implementação\n"
      ],
      "metadata": {
        "id": "DFYW04wjZtDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importanto biblioteca\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "8liRcfYnTpKX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setando parâmetros da rede mlp\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 1\n",
        "output_size = 1\n",
        "\n",
        "#cada camada intermediária pode ter o mesmo número de unidades computacionais para fins de simplificação ou apenas terem valores diferentes, nessa implementação vamos adotar a segunda abordagem\n",
        "#para cada camada intermediária - hidden layer, terá um valor relacionado a quantidade de unidades computacionais\n",
        "\n",
        "hidden_layer_size = [1]\n",
        "\n",
        "# serão implementadas três funções de ativação para as camadas intermediárias a relu, sigmoid e linear pela qual será indicada, e para a camdada de saída conforme o indicado sigmoid ou linear\n",
        "# mas a relu também é uma opção\n",
        "# a primeira função será para camadas intermediárias e a segunda para a camada de saída\n",
        "\n",
        "activation_functions = ['relu', 'relu']\n",
        "\n",
        "# o número máximo de épocas que o modelo será treinado\n",
        "# o objetivo é que não precise chegar ao número máximo de épocas, quando o modelo apresentar overfitting o treinamento já acabe\n",
        "\n",
        "MAX_EPOCH = 1\n",
        "\n",
        "# taxa de aprendizado que será utilizada\n",
        "\n",
        "learning_rate = 0.03\n",
        "\n",
        "# tamanho dos mini-batchs que será utilizado dos dados de treinamento e teste\n",
        "\n",
        "batch_size_train = 100\n",
        "\n",
        "batch_size_test = 20"
      ],
      "metadata": {
        "id": "MpHczcWLTxNI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setando o gerador de números aleatórios para setar os pesos iniciais\n",
        "\n",
        "weigths_seed = 115\n",
        "rng = np.random.default_rng(weigths_seed)\n",
        "\n",
        "# como a rede mlp é totalmente conectada, o número de pesos gerados entre camadas segirá sempre o padrão layer[i]*layer[i+1]\n",
        "\n",
        "weights = []\n",
        "\n",
        "for i in range(hidden_size+1):\n",
        "\n",
        "  if i == 0:\n",
        "\n",
        "    weights.append(rng.random(size = (input_size, hidden_layer_size[i], 1)))\n",
        "\n",
        "  elif i < hidden_size:\n",
        "\n",
        "    weights.append(rng.random((hidden_layer_size[i-1], hidden_layer_size[i], 1)))\n",
        "\n",
        "  else:\n",
        "\n",
        "    weights.append(rng.random((hidden_layer_size[i-1], output_size, 1)))\n",
        "\n"
      ],
      "metadata": {
        "id": "xJc4i5gCWSGx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# primeiro index é para referir a qual camada, sempre haverá hidden_layers+1 camada de pesos\n",
        "# o segundo index para referenciar qual unidade computacional da camada\n",
        "# o terceiro index para referenciar o peso a qual unidade computacional da próxima camada\n",
        "# o quarto index para obter o valor\n",
        "\n",
        "print(weights[0][0][0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1hNLJNRkptI",
        "outputId": "8e27fad5-3ecc-45a1-a13e-74f1d4d76d78"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7023380241887802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções para o treinamento da rede MLP\n",
        "\n",
        "#### fase foward e backward\n"
      ],
      "metadata": {
        "id": "dvqQTwlOr02t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# funções de ativação\n",
        "\n",
        "# função relu normal\n",
        "def function_Relu(x):\n",
        "\n",
        "  return max(0, x)\n",
        "\n",
        "# função sigmoid normal\n",
        "def function_Sigmoid(x):\n",
        "\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "# função linear entre 0 e 1\n",
        "def function_Linear(x):\n",
        "\n",
        "  return max(0, min(1, x))"
      ],
      "metadata": {
        "id": "_n-jDHSrSlOC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# funções de custo\n",
        "\n",
        "def mean_square_loss(labels, predictions):\n",
        "\n",
        "  loss = 0\n",
        "\n",
        "  for l, p in zip(labels, predictions):\n",
        "      loss = loss + (l - p) ** 2\n",
        "\n",
        "  loss = loss / len(labels)\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "Offq8LMhrbZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# processo de foward da rede\n",
        "\n",
        "def foward(input_size, hidden_size, output_size, hidden_layer_size, activation_functions, weights, data):\n",
        "\n",
        "  # o resultado de cada valor multiplicado pelo seu peso será armazenado no valor parcial\n",
        "\n",
        "  resultado_parcial = [[[] for j in range(hidden_layer_size[i])] for i in range(hidden_size)]\n",
        "\n",
        "  resultado_parcial.append([[]for i in range(output_size)])\n",
        "\n",
        "  # calcular o resultado camada por camada\n",
        "\n",
        "  for i in range(hidden_size+1):\n",
        "\n",
        "    # no primeiro caso será a camada de dados\n",
        "\n",
        "    if i == 0:\n",
        "\n",
        "      input = data\n",
        "\n",
        "    # o caso em que estamos calculando o resuldado das camadas intermediárias\n",
        "\n",
        "    if(i < hidden_size):\n",
        "\n",
        "      for j in range(len(input)):\n",
        "\n",
        "        for k in range(hidden_layer_size[i]):\n",
        "\n",
        "          resultado_parcial[i][k].append(weights[i][j][k][0]*input[j])\n",
        "\n",
        "\n",
        "      aux = np.zeros(hidden_layer_size[i])\n",
        "\n",
        "      for j in range(hidden_layer_size[i]):\n",
        "\n",
        "        aux[j] = np.sum(resultado_parcial[i][j])\n",
        "\n",
        "      # após ter os resultados parciais da soma ponderada das entradas daquela camada, esse valor irá passar pela função de ativação\n",
        "\n",
        "      if activation_functions[0] == 'relu':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Relu(aux[j])\n",
        "\n",
        "      elif activation_functions[0] == 'sigmoid':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Sigmoid(aux[j])\n",
        "\n",
        "      elif activation_functions[0] == 'linear':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Linear(aux[j])\n",
        "\n",
        "\n",
        "    # para o caso contrário\n",
        "\n",
        "    else:\n",
        "\n",
        "      for j in range(len(input)):\n",
        "\n",
        "        for k in range(output_size):\n",
        "\n",
        "          resultado_parcial[i][k].append(weights[i][j][k][0]*input[j])\n",
        "\n",
        "      aux = np.zeros(output_size)\n",
        "\n",
        "      for j in range(output_size):\n",
        "\n",
        "        aux[j] = np.sum(resultado_parcial[i][j])\n",
        "\n",
        "      # após ter os resultados parciais da soma ponderada das entradas daquela camada, esse valor irá passar pela função de ativação\n",
        "\n",
        "      if activation_functions[0] == 'relu':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Relu(aux[j])\n",
        "\n",
        "      elif activation_functions[0] == 'sigmoid':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Sigmoid(aux[j])\n",
        "\n",
        "      elif activation_functions[0] == 'linear':\n",
        "\n",
        "        for j in range(len(aux)):\n",
        "\n",
        "          aux[j] = function_Linear(aux[j])\n",
        "\n",
        "    # após ter o resultado parcial da camada, o input da próxima iteração será o resultado dessa\n",
        "\n",
        "    input = aux\n",
        "\n",
        "  return input\n"
      ],
      "metadata": {
        "id": "OSa5J3HDGoT7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o treinamento fará no máximo MAX_EPOCH iterações\n",
        "# ele irá parar quando a acurácia dos testes diminuir em 5 épocas seguidas\n",
        "# após o processo de treinamento será retornado os pesos ótimos para o problema encontrado\n",
        "\n",
        "def treinamento(input_size, hidden_size, output_size, hidden_layer_size, activation_functions, MAX_EPOCH, learning_rate, batch_size_train, batch_size_test, weights, data_train, data_test, data_train_label, data_test_label):\n",
        "\n",
        "  for epoch in range(MAX_EPOCH):\n",
        "\n",
        "    # atualizando os batchs de treino e de teste\n",
        "\n",
        "    batch_index = rng.integers(len(data_train), size = batch_size_train)\n",
        "\n",
        "    batch_train = data_train[batch_index]\n",
        "\n",
        "    batch_train_label = data_train_label[batch_index]\n",
        "\n",
        "    batch_index = rng.integers(len(data_test), size = batch_size_test)\n",
        "\n",
        "    batch_test = data_test[batch_index]\n",
        "\n",
        "    batch_test_label = data_test_label[batch_index]\n",
        "\n",
        "    # atualizando os pesos de acordo com o erro no batch do treino\n",
        "    # a função de custo será a MSE para regressão, e cross entropy para problemas de classificação\n",
        "\n",
        "    for i in range(batch_size_train):\n",
        "\n",
        "      #resultado do processo de foward\n",
        "\n",
        "      foward_result = foward(input_size, hidden_size, output_size, hidden_layer_size, activation_functions, weights, batch_train[i])\n",
        "\n",
        "      # atualizando os pesos\n",
        "\n",
        "\n",
        "  return weights"
      ],
      "metadata": {
        "id": "_05HMXoItKrt"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "treinamento(input_size, hidden_size, output_size, hidden_layer_size, activation_functions, MAX_EPOCH, learning_rate, data, data, weights, data, data, data, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNRs33jhk59a",
        "outputId": "8df30f0f-e101-42ae-e199-3c2156c244a6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.71071042]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[0.70233802]],\n",
              " \n",
              "        [[0.60370907]]]),\n",
              " array([[[0.54416906]]])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    }
  ]
}